#program options
[MAIN]
DATA_FILE : "data.txt" #!param d
FOREST_FILE : "output/forest.data" #!param f
VERBOSE_FILE : "output/verbose.cpp" #!param v
INITIAL_FOREST_FILE : "" #!param initalforest
THREAD_NUM : 8
RAND_SEED : 1
#if all data fit in one-single machine memory, you can set
#this configure to 0, this can speed up your training a bit.
#NOTE: by this way, you should NOT use some POST-REFINE function(except Null).
SMALL_DATA_RELOAD_OPEN : 1
TRAIN_TREE_0 : 1
#GBDT meta parameters
[GBDT_META_PARAS]
TREE_NUM : 100
SHRINKAGE : 0.01
MAX_DEPTH : 6
EXPECT_MAX_FOREST_NODE_NUM : 1000000000
EXPECT_MAX_TREE_NODE_NUM : 20000000
MIN_NODE_SIZE : 10
#training objection
[OBJECTIVE]
TYPE : ObjectiveMSE
#feature sampling strategy
[FEA_SAMPLE]
TYPE : FeaSampleRandom
FEA_SAMPLE_RATIO : 1.0
#personal configure for FeaSampleFirstTreeOneFea
[FEA_SAMPLE_FIRST_TREE_ONE_FEA]
FEA_ID : 81
#instance sampling strategy
[INS_SAMPLE]
TYPE : InsSampleRandom
INS_SAMPLE_RATIO : 1.0
PARTITION_NUM : 64
SAMPLE_SIZE : 20000000000
SPLIT_NUM : 256
#stop criterion
[CRITERION]
TYPE : CriterionBasic

#para adapt
[PARA_ADAPT]
TYPE : ParaAdaptNull
#post refine
[POST_REFINE]
TYPE : PostRefineNull
#GBDT feature type and split type

[SPLIT_NUM_PV_BINARY_ARG]
PV_BEGIN : 0
PV_STEP : 25
PV_END : 75
IS_PV_LEFT_SPLIT : 0

[PARA_ADAPT_SHRINKAGE_DESCENT_ARG]
START : 1.0
END : 0.1

[ASYNC_REMOVE_BIAS_ARG]
DELIMITER : ,
BIAS_SLOTS : 300,301
BIAS_TREE_SHRINKAGE : 0.2

[ASYNC_REMOVE_BIAS_WITH_DELETION_ARG]
BIAS_TREE_NUM : 2
BIAS_TREE_SHRINKAGE : 1
DEL_TREE_SHRINKAGE : 0.2
BIAS_RETRAIN_OPEN : 1
DELIMITER : ,
BIAS_SLOTS : 300,301

[FEATURE_SPLIT]

